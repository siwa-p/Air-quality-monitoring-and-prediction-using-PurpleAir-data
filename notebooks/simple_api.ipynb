{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_sensors_list(nwlng, nwlat, selng, selat, location, key_read):\n",
    "    # PurpleAir API URL\n",
    "    root_url = 'https://api.purpleair.com/v1/sensors/'\n",
    "\n",
    "    # Constructing lat_lon parameters\n",
    "    lat_lon = {\n",
    "        'nwlng': nwlng,\n",
    "        'nwlat': nwlat,\n",
    "        'selng': selng,\n",
    "        'selat': selat\n",
    "    }\n",
    "    ll_api_url = ''.join([f'&{key}={value}' for key, value in lat_lon.items()])\n",
    "\n",
    "    # Fields to retrieve\n",
    "    fields_list = ['sensor_index', 'name', 'latitude', 'longitude', 'location_type']\n",
    "    fields_api_url = '&fields=' + ','.join(fields_list)\n",
    "\n",
    "    # Indoor, outdoor, or all\n",
    "    if location == 'indoor':\n",
    "        loc_api = '&location_type=1'\n",
    "    elif location == 'outdoor':\n",
    "        loc_api = '&location_type=0'\n",
    "    else:\n",
    "        loc_api = ''\n",
    "\n",
    "    # Final API URL\n",
    "    api_url = f\"{root_url}?api_key={key_read}{fields_api_url}{ll_api_url}{loc_api}\"\n",
    "\n",
    "    # Getting data\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_data = response.json().get('data', [])\n",
    "        if json_data:\n",
    "            df = pd.DataFrame.from_records(json_data, columns=fields_list)\n",
    "        else:\n",
    "            df = pd.DataFrame(columns=fields_list)\n",
    "    else:\n",
    "        raise requests.exceptions.RequestException(f\"Failed to fetch data from {api_url}\")\n",
    "\n",
    "    # Saving to PostgreSQL (optional)\n",
    "    # df.to_sql('tablename', con=engine, if_exists='append', index=False)\n",
    "\n",
    "    # Saving to CSV file\n",
    "    df.to_csv(\"../datasets/sensor_data/sensor_list\", index=False, header=True)\n",
    "\n",
    "    # Creating a list of sensor indices\n",
    "    sensors_list = df['sensor_index'].tolist()\n",
    "\n",
    "    return sensors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../keys.json') as fi:\n",
    "    credentials = json.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12999, 51703, 51749, 51873, 51921, 54613, 54619, 84545, 93645, 94657, 116559, 122237, 172663]\n"
     ]
    }
   ],
   "source": [
    "# nwlng = -87.1  # Northwest longitude of the bounding box\n",
    "# nwlat = 36.5   # Northwest latitude of the bounding box\n",
    "# selng = -86.6  # Southeast longitude of the bounding box\n",
    "# selat = 35.9   # Southeast latitude of the bounding box\n",
    "# location = 'outdoor'  # You can specify 'indoor', 'outdoor', or 'all'\n",
    "# keys_file_path = '../keys.json'  # Path to your keys.json file\n",
    "\n",
    "# sensors_list = get_sensors_list(nwlng, nwlat, selng, selat, location, credentials['api_key'])\n",
    "# print(sensors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_index</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12999</td>\n",
       "      <td>Roberts Road</td>\n",
       "      <td>0</td>\n",
       "      <td>36.372610</td>\n",
       "      <td>-86.840126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51703</td>\n",
       "      <td>NearRdD140</td>\n",
       "      <td>0</td>\n",
       "      <td>36.142494</td>\n",
       "      <td>-86.734150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51749</td>\n",
       "      <td>NearRdB4C3</td>\n",
       "      <td>0</td>\n",
       "      <td>36.142340</td>\n",
       "      <td>-86.734210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51873</td>\n",
       "      <td>LockelandD6CD</td>\n",
       "      <td>0</td>\n",
       "      <td>36.176247</td>\n",
       "      <td>-86.739105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51921</td>\n",
       "      <td>Lockeland3975</td>\n",
       "      <td>0</td>\n",
       "      <td>36.176340</td>\n",
       "      <td>-86.738976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54613</td>\n",
       "      <td>TAP1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.166560</td>\n",
       "      <td>-86.801230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54619</td>\n",
       "      <td>TAP3</td>\n",
       "      <td>0</td>\n",
       "      <td>36.126570</td>\n",
       "      <td>-86.801940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84545</td>\n",
       "      <td>NearRd(Rep)102F</td>\n",
       "      <td>0</td>\n",
       "      <td>36.142414</td>\n",
       "      <td>-86.733986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93645</td>\n",
       "      <td>LockelandCCEA</td>\n",
       "      <td>0</td>\n",
       "      <td>36.176190</td>\n",
       "      <td>-86.738850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94657</td>\n",
       "      <td>Shelby Hills</td>\n",
       "      <td>0</td>\n",
       "      <td>36.169582</td>\n",
       "      <td>-86.740524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>116559</td>\n",
       "      <td>HIDE6</td>\n",
       "      <td>0</td>\n",
       "      <td>36.176994</td>\n",
       "      <td>-86.742830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>122237</td>\n",
       "      <td>Cayce 4</td>\n",
       "      <td>0</td>\n",
       "      <td>36.164864</td>\n",
       "      <td>-86.757730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>172663</td>\n",
       "      <td>Walk Bike Nashville Office</td>\n",
       "      <td>0</td>\n",
       "      <td>36.174160</td>\n",
       "      <td>-86.760560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sensor_index                        name  latitude  longitude  \\\n",
       "0          12999                Roberts Road         0  36.372610   \n",
       "1          51703                  NearRdD140         0  36.142494   \n",
       "2          51749                  NearRdB4C3         0  36.142340   \n",
       "3          51873               LockelandD6CD         0  36.176247   \n",
       "4          51921               Lockeland3975         0  36.176340   \n",
       "5          54613                        TAP1         0  36.166560   \n",
       "6          54619                        TAP3         0  36.126570   \n",
       "7          84545             NearRd(Rep)102F         0  36.142414   \n",
       "8          93645               LockelandCCEA         0  36.176190   \n",
       "9          94657                Shelby Hills         0  36.169582   \n",
       "10        116559                       HIDE6         0  36.176994   \n",
       "11        122237                     Cayce 4         0  36.164864   \n",
       "12        172663  Walk Bike Nashville Office         0  36.174160   \n",
       "\n",
       "    location_type  \n",
       "0      -86.840126  \n",
       "1      -86.734150  \n",
       "2      -86.734210  \n",
       "3      -86.739105  \n",
       "4      -86.738976  \n",
       "5      -86.801230  \n",
       "6      -86.801940  \n",
       "7      -86.733986  \n",
       "8      -86.738850  \n",
       "9      -86.740524  \n",
       "10     -86.742830  \n",
       "11     -86.757730  \n",
       "12     -86.760560  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sensor_list')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading for PA: 12999 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 12999 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 12999 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 12999 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 12999 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 12999 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 12999 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 51703 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 51703 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 51703 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 51703 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 51703 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 51703 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 51703 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 51749 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 51749 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 51749 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 51749 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 51749 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 51749 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 51749 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 51873 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 51873 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 51873 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 51873 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 51873 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 51873 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 51873 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 51921 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 51921 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 51921 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 51921 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 51921 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 51921 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 51921 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 54613 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54613 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54613 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54613 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54613 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54613 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54613 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54619 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54619 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54619 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54619 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54619 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54619 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 54619 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 84545 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 84545 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 84545 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 84545 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 84545 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 84545 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 84545 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 93645 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 93645 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 93645 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 93645 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 93645 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 93645 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 93645 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 94657 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 94657 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 94657 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 94657 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 94657 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 94657 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 94657 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 116559 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 116559 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 116559 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 116559 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 116559 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 116559 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 116559 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 122237 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "Downloading for PA: 122237 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "Downloading for PA: 122237 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "Downloading for PA: 122237 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "Downloading for PA: 122237 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "Downloading for PA: 122237 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "Downloading for PA: 122237 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "Downloading for PA: 172663 for Dates: 2022-06-13T00:00:00Z and 2022-06-15T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 172663 for Dates: 2022-06-11T00:00:00Z and 2022-06-13T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 172663 for Dates: 2022-06-09T00:00:00Z and 2022-06-11T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 172663 for Dates: 2022-06-07T00:00:00Z and 2022-06-09T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 172663 for Dates: 2022-06-05T00:00:00Z and 2022-06-07T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 172663 for Dates: 2022-06-03T00:00:00Z and 2022-06-05T00:00:00Z.\n",
      "------------- No Data Available -------------\n",
      "Downloading for PA: 172663 for Dates: 2022-06-01T00:00:00Z and 2022-06-03T00:00:00Z.\n",
      "------------- No Data Available -------------\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Starting engine for postgresql\n",
    "# engine = create_engine('postgresql://postgres:password@location:port/database')\n",
    "\n",
    "# API Keys provided by PurpleAir(c)\n",
    "key_read  = credentials['api_key']\n",
    "\n",
    "# Sleep Seconds\n",
    "sleep_seconds = 3 # wait sleep_seconds after each query\n",
    "\n",
    "\n",
    "def get_historicaldata(sensors_list,bdate,edate,average_time,key_read):\n",
    "    # Historical API URL\n",
    "    root_api_url = 'https://api.purpleair.com/v1/sensors/'\n",
    "    \n",
    "    # Average time: The desired average in minutes, one of the following:0 (real-time),10 (default if not specified),30,60\n",
    "    average_api = f'&average={average_time}'\n",
    "\n",
    "    # Creating fields api url from fields list to download the data: Note: Sensor ID/Index will not be downloaded as default\n",
    "    fields_list = ['pm2.5_atm_a', 'pm2.5_atm_b', 'pm2.5_cf_1_a', 'pm2.5_cf_1_b', 'humidity_a', 'humidity_b', \n",
    "               'temperature_a', 'temperature_b', 'pressure_a', 'pressure_b']\n",
    "    for i,f in enumerate(fields_list):\n",
    "        if (i == 0):\n",
    "            fields_api_url = f'&fields={f}'\n",
    "        else:\n",
    "            fields_api_url += f'%2C{f}'\n",
    "\n",
    "    # Dates of Historical Data period\n",
    "    begindate = datetime.fromisoformat(bdate)\n",
    "    enddate   = datetime.fromisoformat(edate)\n",
    "    \n",
    "    # Downlaod days based on average\n",
    "    if (average_time == 60):\n",
    "        datelist = pd.date_range(begindate,enddate,freq='14d') # for 14 days of data\n",
    "    else:\n",
    "        datelist = pd.date_range(begindate,enddate,freq='2d') # for 2 days of data\n",
    "        \n",
    "    # Reversing to get data from end date to start date\n",
    "    datelist = datelist.tolist()\n",
    "    datelist.reverse()\n",
    "    \n",
    "    # Converting to PA required format\n",
    "    date_list=[]\n",
    "    for dt in datelist:\n",
    "        dd = dt.strftime('%Y-%m-%d') + 'T' + dt.strftime('%H:%M:%S') +'Z'\n",
    "        date_list.append(dd)\n",
    "\n",
    "    # to get data from end date to start date\n",
    "    len_datelist = len(date_list) - 1\n",
    "        \n",
    "    # Getting 2-data for one sensor at a time\n",
    "    for s in sensors_list:\n",
    "        # Adding sensor_index & API Key\n",
    "        hist_api_url = root_api_url + f'{s}/history/csv?api_key={key_read}'\n",
    "\n",
    "        # Creating start and end date api url\n",
    "        for i,d in enumerate(date_list):\n",
    "            # Wait time \n",
    "            time.sleep(sleep_seconds)\n",
    "            \n",
    "            if (i < len_datelist):\n",
    "                print('Downloading for Nashville: %s for Dates: %s and %s.' %(s,date_list[i+1],d))\n",
    "                dates_api_url = f'&start_timestamp={date_list[i+1]}&end_timestamp={d}'\n",
    "            \n",
    "                # Final API URL\n",
    "                api_url = hist_api_url + dates_api_url + average_api + fields_api_url\n",
    "                            \n",
    "                #\n",
    "                try:\n",
    "                    response = requests.get(api_url)\n",
    "                except:\n",
    "                    print(api_url)\n",
    "                #\n",
    "                try:\n",
    "                    assert response.status_code == requests.codes.ok\n",
    "                \n",
    "                    # Creating a Pandas DataFrame\n",
    "                    df = pd.read_csv(StringIO(response.text), sep=\",\", header=0)\n",
    "                \n",
    "                except AssertionError:\n",
    "                    df = pd.DataFrame()\n",
    "                    print('Bad URL!')\n",
    "            \n",
    "                if df.empty:\n",
    "                    print('------------- No Data Available -------------')\n",
    "                else:\n",
    "                    # Dropping duplicate rows\n",
    "                    df = df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "                    \n",
    "                    # writing to csv file\n",
    "                    filename = ('../datasets/sensor_data/\\sensorsID_%s_%s_%s.csv' % (s,date_list[i+1],d))\n",
    "                    df.to_csv(filename, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data download period\n",
    "bdate = '2022-06-01T00:00:00+00:00' \n",
    "edate = '2022-06-15T00:00:00+00:00'\n",
    "\n",
    "df = pd.read_csv(\"../datasets/sensor_data/sensor_list_01\")\n",
    "\n",
    "# Creating a list of sensor indices\n",
    "sensors_list = df['sensor_index'].tolist()\n",
    "\n",
    "# Average_time. The desired average in minutes, one of the following: 0 (real-time), \n",
    "#                  10 (default if not specified), 30, 60, 360 (6 hour), 1440 (1 day)\n",
    "average_time=360  # or 10  or 0 (Current script is set only for real-time, 10, or 60 minutes data)\n",
    "\n",
    "# Getting Nashville_area data\n",
    "# get_historicaldata(sensors_list, bdate, edate, average_time, key_read)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_msdso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
